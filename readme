We start with letting user make a project. In the project, we should first ask project names, the configuration, data owners (may be not MVP), like adding names of all domains (we can think of setting project level configuration)

Then depending on the input domains you have configured, you have option to upload its schema and sample data (let sample data be optional for now) Open question: can we make it either or?

There is no limit to how many schemas can be there. The structure of the data should be as follows: (Check 01_input folder)
file 1: Schema1_Schema → Schema definition -> field_name | description | data_type |	length |	nullable |	primary_key |	foreign_key_ref |	example_values |	tags
file 2: Schema1_Data   → Sample data  -> Depending on field_names suggested in schema file (could be a control to check, also check the data type, length etc)

Question: As long as we have example values, do we care for sample file? 

There should be separate target schema file :
Sheet 1: Target_Schema → Target definition -> field_name | description | data_type |	length |	nullable |	primary_key |	foreign_key_ref |	example_values |	tags
Sheet 2: Target_Data   → Target sample -> Depending on field_names suggested in schema file (could be a control to check, also check the data type, length etc)

and then there is 3rd file which is really to be used for validation and also guide the program what should be the format of the output:

Sheet 1: Mappings → target_field | source_fields | transform_dsl | example_expression | notes

Profiler

Profller: examining and analyzing source data files to understand their structure, content patterns, and data quality characteristics.
•  DATA_TYPE: What type of data each column contains (numeric, categorical, etc.) 
•  RECORDS: Total number of records/rows 
•  POPULATION_PERCENTAGE: How much of the data is populated vs empty 
•  DISTINCT_COUNT: Number of unique values 
•  NULL_COUNT: Number of empty/missing values 
•  MOST_COMMON_VALUES: Frequently occurring values in each field 
•  MIN_LENGTH / MAX_LENGTH: Size ranges for text fields 
•  MIN_VALUE / MAX_VALUE: Value ranges for numeric fields 
•  LEADING_TRAILING_SPACES_COUNT: Data quality issues

This could only be example, as profilers we should be able to get more attributes. 

Output of profiler

JSON template with multiple sheets: (TBD)

source_schema_structure: all fields of all tables including their connection details
Field_Profiles: Complete profiling metrics for every field (including target)
Schema_Summary: Summary statistics by schema
Quality_Issues: Fields with data quality problems (for example if the sample data doesnt match the description)




